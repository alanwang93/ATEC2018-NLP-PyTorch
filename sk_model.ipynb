{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "from utils import init_log, score\n",
    "from sk_models.logistic_regressor import LogisticRegressor\n",
    "from sk_models.random_forest_classifier import RandomForest\n",
    "from sk_models.bagging_classifier import Bagging\n",
    "from sk_models.adaboost_classifier import AdaBoost\n",
    "from sk_models.mlp_classifier import MLP\n",
    "from sk_models.sk_model import SKModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.disable()\n",
    "train_data_path = 'data/processed/train.pkl'\n",
    "data = pickle.load(open(train_data_path, 'r'))\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = init_log('log/sk_model.log')\n",
    "sk_train_path = 'data/processed/sk_train.pkl'\n",
    "\n",
    "# Pair level or sentence level features\n",
    "rebuild = True\n",
    "features = ['s1_wlen', 's1_clen', 'jaccard_char_unigram', 'jaccard_char_bigram',\\\n",
    " \t\t\t'jaccard_char_trigram', 'jaccard_word_unigram',# 'LevenshteinDistance_char',\\\n",
    " \t\t\t'LevenshteinDistance_word', 'word_bool', 's1_word_lsa', 's1_char_lsa']\n",
    "# features = ['s1_word_lsa']\n",
    "# features = ['s1_char_lsa', 's1_word_lsa']\n",
    "# logger.info(\"Loading training data\")\n",
    "if rebuild or not os.path.exists(sk_train_path):\n",
    "#     logger.info(\"Processing training data\")\n",
    "    X_features = []\n",
    "    for feat in features:\n",
    "        if data[feat][0] == 's':\n",
    "            X_features.append((data[feat][1]*data[feat.replace('1', '2')][1]).reshape(-1,data[feat][2]))\n",
    "            X_features.append(np.abs(data[feat][1]-data[feat.replace('1', '2')][1]).reshape(-1,data[feat][2]))\n",
    "        elif data[feat][0] == 'p':\n",
    "            if feat == 'word_bool':\n",
    "                X_features.append(np.squeeze(data[feat][1]))\n",
    "            elif len(data[feat][1].shape) == 1:\n",
    "                X_features.append(data[feat][1].reshape(-1,1))\n",
    "#                 X_features.append(np.power(data[feat][1].reshape(-1,1), 2))\n",
    "            else:\n",
    "                X_features.append(np.squeeze(data[feat][1]))\n",
    "#                 X_features.append(np.power(np.squeeze(data[feat][1]), 2))\n",
    "\n",
    "#     for f in X_features:\n",
    "#         print(f.shape)\n",
    "    X = np.concatenate(X_features, axis=1)\n",
    "    y = data['label'][1]\n",
    "#     del data\n",
    "#     pickle.dump({\"X\":X, \"y\":y}, open(sk_train_path, 'w'))\n",
    "else:\n",
    "    data = pickle.load(open(sk_train_path, 'r'))\n",
    "    X = data['X']\n",
    "    y = data['y']\n",
    "#     del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of features', 533)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=666)\n",
    "print(\"Number of features\", X_train.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    {\n",
    "        'module': 'linear_model',\n",
    "        'clf': 'LogisticRegression',\n",
    "        'kwargs': {\n",
    "            'class_weight': 'balanced', \n",
    "            'C':10.,\n",
    "        }\n",
    "    }\n",
    "]\n",
    "preds = []\n",
    "for c in configs:\n",
    "    clf = SKModel(c)\n",
    "    # print(clf.clf)\n",
    "    clf.fit(X_train, y_train)\n",
    "    # score = clf.score(valid_X, valid_y)\n",
    "    pred = clf.predict(X_test)\n",
    "    preds.append(pred)\n",
    "    print(c['clf'])\n",
    "    print(clf.score(X_test, y_test))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.4, (0.3763045158473518, 0.5161007025257512, 0.24352922021104847, 0.8274336278609327))\n",
      "(0.41000000000000003, (0.379091373931204, 0.5317135050222762, 0.24742442150862615, 0.810287610171301))\n",
      "(0.42000000000000004, (0.38207886896916166, 0.5464480873783716, 0.2514875743347064, 0.7948008845161499))\n",
      "(0.43000000000000005, (0.38328060049806373, 0.5594262294536079, 0.2544893886714149, 0.7759955747920378))\n",
      "(0.44000000000000006, (0.38685170692205995, 0.5740632317941, 0.2592732065036202, 0.7616150438265403))\n",
      "(0.45000000000000007, (0.38977873928493617, 0.5875292739473527, 0.26372338342181606, 0.746681415516216))\n",
      "(0.4600000000000001, (0.3940604831364429, 0.6017759562254317, 0.2693322508079293, 0.733960176585199))\n",
      "(0.4700000000000001, (0.39553681528439927, 0.614071038191445, 0.2732840548525271, 0.7157079642059136))\n",
      "(0.4800000000000001, (0.3974050652578424, 0.628317720469524, 0.2783071127236191, 0.6946902651024943))\n",
      "(0.4900000000000001, (0.4013690004920061, 0.6416861826071735, 0.2845584835218311, 0.6808628314818236))\n",
      "(0.5000000000000001, (0.4012809788396306, 0.6534933644951704, 0.28862478770588773, 0.6581858403439237))\n",
      "(0.5100000000000001, (0.39999956852713636, 0.6636416861179116, 0.2918465836190382, 0.6355088492060238))\n",
      "(0.5200000000000001, (0.40208927417677615, 0.6761319281151316, 0.29815655883030817, 0.6172566368267386))\n",
      "(0.5300000000000001, (0.40007398581137915, 0.6854020295974432, 0.3014582164045266, 0.5945796456888387))\n",
      "(0.5400000000000001, (0.4016925049900746, 0.6965261513762172, 0.3079646016790665, 0.577433627999207))\n",
      "(0.5500000000000002, (0.4004777218165854, 0.7063817329521486, 0.312986608435694, 0.5558628315509608))\n",
      "(0.5600000000000002, (0.39868021663833764, 0.7153590943876503, 0.3177785079468359, 0.5348451324475414))\n",
      "(0.5700000000000002, (0.39829739876851195, 0.7240437157763423, 0.323651452170245, 0.5176991147579098))\n",
      "(0.5800000000000002, (0.39531236538860176, 0.7331186572274474, 0.3292817678345187, 0.494469026275183))\n",
      "(0.5900000000000002, (0.39567966117797065, 0.7433645588657919, 0.3384433960933792, 0.47621681389589776))\n",
      "(0.6000000000000002, (0.38977739303987297, 0.7506830600360379, 0.34300126088986915, 0.4513274333786905))\n",
      "(0.6100000000000002, (0.38620984672426106, 0.7602459015651595, 0.35216400895117816, 0.427544247551137))\n",
      "(0.6200000000000002, (0.38572856086864554, 0.7681498828290252, 0.36213592215430296, 0.41261061924081266))\n",
      "(0.6300000000000002, (0.38314948682293143, 0.7756635440304778, 0.3720687856320642, 0.39491150420635424))\n",
      "(0.6400000000000002, (0.37541662995194036, 0.7808352848574517, 0.37751677831235075, 0.373340707758108))\n",
      "(0.6500000000000002, (0.3680087736049909, 0.7871779858716649, 0.38648813123159576, 0.3512168139650349))\n",
      "(0.6600000000000003, (0.3603490066496105, 0.7928376267766551, 0.3957643941788455, 0.33075221220644235))\n",
      "(0.6700000000000003, (0.34989016735525735, 0.7969359874319929, 0.40201004996266326, 0.3097345131030229))\n",
      "(0.6800000000000003, (0.3420962366984552, 0.8022053082745702, 0.41398271766379985, 0.29148230072373765))\n",
      "(0.6900000000000003, (0.3301818334038503, 0.8064012489455111, 0.42374350049935566, 0.2704646016203182))\n",
      "(0.7000000000000003, (0.31840401360520454, 0.8099141295072293, 0.43333333292063486, 0.2516592918962061))\n",
      "(0.7100000000000003, (0.3018046005736065, 0.8112802497256753, 0.43451143405975945, 0.23119469013761354))\n",
      "(0.7200000000000003, (0.2873213937315039, 0.8145979702561867, 0.4463869458666819, 0.2118362830686746))\n",
      "(0.7300000000000003, (0.27315133358691385, 0.8177205307554917, 0.4606299206553413, 0.19413716803421616))\n",
      "(0.7400000000000003, (0.254018895175919, 0.8188914909427311, 0.4647058816695502, 0.17477876096527722))\n",
      "(0.7500000000000003, (0.23758240461072913, 0.820257611161177, 0.4720394729078298, 0.15873893796529925))\n",
      "(0.7600000000000003, (0.21976114477999062, 0.8212334113172098, 0.4777777768930041, 0.14269911496532128))\n",
      "(0.7700000000000004, (0.20641161826561924, 0.8236729117072918, 0.5010660970126523, 0.12997787603430427))\n",
      "(0.7800000000000004, (0.19441913856167337, 0.8253317719725476, 0.5217391291745431, 0.11946902648259455))\n",
      "(0.7900000000000004, (0.17250894797654068, 0.8249414519101345, 0.5194444430015432, 0.10342920348261658))\n",
      "(0.8000000000000004, (0.14933812540912803, 0.8243559718165148, 0.5129870113214707, 0.08738938048263861))\n",
      "(0.8100000000000004, (0.13198436075695086, 0.8241608117853082, 0.5111940279433058, 0.07577433624127525))\n",
      "(0.8200000000000004, (0.1165430184075076, 0.8254293519881509, 0.5437787993374249, 0.06526548668956554))\n",
      "(0.8300000000000004, (0.09292913419065886, 0.8247462918789279, 0.5348837178204435, 0.05088495572406805))\n",
      "(0.8400000000000004, (0.0770414697962525, 0.8246487118633247, 0.5395683414419544, 0.041482300862011996))\n",
      "(0.8500000000000004, (0.06448246678417087, 0.8244535518321181, 0.539130430094518, 0.03429203537926325))\n",
      "(0.8600000000000004, (0.04968279035923919, 0.8245511318477213, 0.5595238028628119, 0.02599557520686085))\n",
      "(0.8700000000000004, (0.0364025073778272, 0.8243559718165148, 0.5666666572222224, 0.018805309724112106))\n",
      "(0.8800000000000004, (0.024905210393778836, 0.8242583918009115, 0.5897435746219597, 0.012721238931017013))\n",
      "(0.8900000000000005, (0.017429163844915718, 0.8239656517541016, 0.5714285510204089, 0.008849557517229226))\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.4, 0.9, 0.01):\n",
    "    print(i, clf.score(X_test, y_test, threshold=i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py2)",
   "language": "python",
   "name": "py2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
